# Data Engineering on GCP

## Getting Started with Data Engineering on GCP
* Setup Google Cloud SDK
* Setup Development Environment to interact with GCP

## Setting up Data Lake using GCS
* Setup GCS Bucket
* Overview of GCS Web UI
* Overview of gsutil
* Overview of Data Sets
* Manage Files in GCS using gsutil commands
* Copy Data Set to GCS using gsutil commands
* Manage Files in GCS using Python
* Overview of processing data in GCS using Pandas

## Data Warehouse using Google Big Query
* Getting Started with Google Big Query
* Overview of Running Queries using Public Data Sets
* Setup Database for Data in Google Big Query
* Setup Tables and Load Data using Google Big Query
* Python Pandas Integration with Google Big Query

## Big Data Processing using Google Dataproc
* Overview of GCP Dataproc
* Setup Single Node Hadoop and Spark Cluster using Dataproc
* Setup Remote Development Environment using VS Code
* Review Data Sets
* Run Spark SQL Commands or Scripts using Dataproc
* Run Pyspark Applications using Dataproc
* Review Spark Jobs on Dataproc using Spark UI
* Integration of Spark on Google Dataproc and Big Query

## Big Data Processing using Databricks on GCP
* Overview of Databricks on GCP
* Overview of DBFS
* Mount GCS Buckets on DBFS
* Run Spark SQL Commands or Scripts using Databricks Workflows
* Run Pyspark Applications using Databricks
* Review Spark Jobs on Dataproc using Spark UI

## Orchestration using Cloud Composer
* Setup Google Cloud Composer (Airflow)
* Airflow Architecture
* Develop Airflow DAGs to orchestrate Dataproc Jobs
* Differences between Dataproc Workflows and Airflow DAGs

## Jenkins
* What is CI/CD?
* Setp env and tools to kickstart on Jenkins
* Build few basic Jenkins Pipelines
